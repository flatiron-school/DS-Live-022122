{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 0
   },
   "source": [
    "# Phase 4 Code Challenge Review\n",
    "\n",
    "Made using resources that Max put together, thanks Max!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "- Principal Component Analysis\n",
    "- Clustering\n",
    "- Time Series\n",
    "- Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Principal Component Analysis\n",
    "\n",
    "![pca gif saved from learnco](images/pca.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: What does PCA do? \n",
    "\n",
    "Specifically, describe what the first principal component represents in relation to the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: What are some reasons to use PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Why is scaling important for PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: How can one determine how many principle components to use in a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer: \n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 16
   },
   "source": [
    "## PCA in Code\n",
    "\n",
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 17
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import  load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data['data'], columns = data['feature_names'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5: Prepare our Data for PCA\n",
    "\n",
    "What steps do we need to take to preprocess our data effectively?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 18
   },
   "outputs": [],
   "source": [
    "# Code to preprocess X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Import PCA, Then Instantiate and Fit a PCA Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 19
   },
   "outputs": [],
   "source": [
    "# Code to import, instantiate and fit a PCA object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7: How Much Variance is Explained by the First 2 Components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 20
   },
   "outputs": [],
   "source": [
    "# Code here to answer the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 83
   },
   "source": [
    "# 2) Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8: Describe how the K-Means algorithm updates its cluster centers after initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9: What is inertia, and how does K-Means use inertia to determine the best estimator?\n",
    "\n",
    "Please also describe the method you can use to evaluate clustering using inertia.\n",
    "\n",
    "Documentation, for reference: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10: What other metric do we have to score the clusters which are formed?\n",
    "\n",
    "Describe the difference between it and inertia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 95
   },
   "source": [
    "## Clustering in Code with Heirarchical Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 96
   },
   "source": [
    "After the above conceptual review of KMeans, let's practice coding with agglomerative clustering.\n",
    "\n",
    "\n",
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 97
   },
   "outputs": [],
   "source": [
    "# New dataset for this section!\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11: Prepare our Data for Clustering\n",
    "\n",
    "What steps do we need to take to preprocess our data effectively?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 99
   },
   "outputs": [],
   "source": [
    "# Code to preprocess the data\n",
    "# Name the processed data X_processed\n",
    "X_processed = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12: Import the Relevant Class, Then Instantiate and Fit a Hierarchical Agglomerative Clustering Object\n",
    "\n",
    "Let's use `n_clusters = 2` to start (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevent clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 100
   },
   "outputs": [],
   "source": [
    "# Fit the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 101
   },
   "outputs": [],
   "source": [
    "# Calculate a silhouette score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13: Write a Function to Test Different Options for `n_clusters`\n",
    "\n",
    "The function should take in the number for `n_clusters` and the data to cluster, fit a new clustering model using that parameter to the data, print the silhouette score, then return the labels attribute from the fit clustering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_n_for_clustering(n, data):\n",
    "    \"\"\" \n",
    "    Tests different numbers for the hyperparameter n_clusters\n",
    "    Prints the silhouette score for that clustering model\n",
    "    Returns the labels that are output from the clustering model\n",
    "\n",
    "    Parameters: \n",
    "    -----------\n",
    "    n: float object\n",
    "        number of clusters to use in the agglomerative clustering model\n",
    "    data: Pandas DataFrame or array-like object\n",
    "        Data to cluster\n",
    "\n",
    "    Returns: \n",
    "    --------\n",
    "    labels: array-like object\n",
    "        Labels attribute from the clustering model\n",
    "    \"\"\"\n",
    "    # Fit the new clustering model\n",
    "    \n",
    "    # Print the silhouette score\n",
    "    \n",
    "    # Return the labels attribute from the fit clustering model\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing your function\n",
    "\n",
    "for n in range(2, 9):\n",
    "    test_n_for_clustering(n, X_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 51
   },
   "source": [
    "# 3) Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 52,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# New dataset for this section!\n",
    "ap = pd.read_csv('data/AirPassengers.csv')\n",
    "ap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14: Prepare our Data for Time Series Analysis\n",
    "\n",
    "What steps do we need to take to preprocess our data effectively?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15: Explore Patterns in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: what kinds of patterns can one find in time series data?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, plot this time series data. What kinds of patterns do you see in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 62
   },
   "outputs": [],
   "source": [
    "# Code to plot the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16: Explore the Moving Average\n",
    "\n",
    "What window would make sense to use for this data?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to create the moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 67
   },
   "outputs": [],
   "source": [
    "# Add to the moving average to the above plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17: Explore Stationarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 69
   },
   "source": [
    "Why do we try to make our data stationary?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 69
   },
   "source": [
    "What can we do to make our data stationary?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18: Check Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 80
   },
   "outputs": [],
   "source": [
    "# Code here to check if the data is stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19: Try to Make the Data Stationarity\n",
    "\n",
    "Implement one strategy to try to make the data more stationary, then check if it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 73
   },
   "outputs": [],
   "source": [
    "# Code here to try to make the data stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here to check if the data is stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 82
   },
   "source": [
    "<a id='clust'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 23
   },
   "source": [
    "# 4) Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Concepts\n",
    "\n",
    "### Some Example Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 24
   },
   "outputs": [],
   "source": [
    "# Each sentence is a document\n",
    "sentence_one = \"Harry Potter is the best young adult book about wizards\"\n",
    "sentence_two = \"Um, EXCUSE ME! Ever heard of Earth Sea?\"\n",
    "sentence_three = \"I only like to read non-fiction.  It makes me a better person.\"\n",
    "\n",
    "# The corpus is composed of all of the documents\n",
    "corpus = [sentence_one, sentence_two, sentence_three]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20: NLP Pre-processing\n",
    "\n",
    "List at least three steps you can take to turn raw text like this into something that would be semantically valuable (aka ready to turn into numbers):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 25
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "1.  \n",
    "2. \n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21: Describe what vectorized text would look like as a dataframe.\n",
    "\n",
    "If you vectorize the above corpus, what would the rows and columns be in the resulting dataframe (aka document term matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 25
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22: What does TF-IDF do?\n",
    "\n",
    "Also, what does TF-IDF stand for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 25
   },
   "source": [
    "#### Answer:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 33
   },
   "source": [
    "## NLP in Code\n",
    "\n",
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 34
   },
   "outputs": [],
   "source": [
    "# New section, new data\n",
    "policies = pd.read_csv('data/2020_policies_feb_24.csv')\n",
    "\n",
    "def warren_not_warren(label):\n",
    "    \n",
    "    '''Make label a binary between Elizabeth Warren\n",
    "    speeches and speeches from all other candidates'''\n",
    "    \n",
    "    if label =='warren':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "policies['candidate'] = policies['candidate'].apply(warren_not_warren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 35
   },
   "source": [
    "The dataframe loaded above consists of policies of 2020 Democratic presidential hopefuls. The `policy` column holds text describing the policies themselves.  The `candidate` column indicates whether it was or was not an Elizabeth Warren policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 36
   },
   "outputs": [],
   "source": [
    "policies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "index": 37
   },
   "source": [
    "The documents for activity are in the `policy` column, and the target is candidate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23: Import the Relevant Class, Then Instantiate and Fit a Count Vectorizer Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First! Train-test split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Code here to train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24: Vectorize Your Text, Then Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 42
   },
   "outputs": [],
   "source": [
    "# Code here to transform train and test sets with the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "index": 44
   },
   "outputs": [],
   "source": [
    "# Importing the classifier...\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Code here to instantiate and fit a Random Forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here to evaluate your model on the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
