{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Spark:-Getting-Started\" data-toc-modified-id=\"Spark:-Getting-Started-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Spark: Getting Started</a></span><ul class=\"toc-item\"><li><span><a href=\"#Optional-Step-0:-Prerequisites-&amp;-Installation-for-Databricks-or-Local-Run\" data-toc-modified-id=\"Optional-Step-0:-Prerequisites-&amp;-Installation-for-Databricks-or-Local-Run-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Optional Step 0: Prerequisites &amp; Installation for Databricks or Local Run</a></span><ul class=\"toc-item\"><li><span><a href=\"#Databricks-Setup\" data-toc-modified-id=\"Databricks-Setup-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Databricks Setup</a></span></li></ul></li><li><span><a href=\"#Step-1:-Create-a-SparkSession-with-a-SparkContext\" data-toc-modified-id=\"Step-1:-Create-a-SparkSession-with-a-SparkContext-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Step 1: Create a SparkSession with a SparkContext</a></span></li><li><span><a href=\"#Step-2:-Download-some-Amazon-reviews-(Toys-&amp;-Games)\" data-toc-modified-id=\"Step-2:-Download-some-Amazon-reviews-(Toys-&amp;-Games)-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Step 2: Download some Amazon reviews (Toys &amp; Games)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Optional:-For-Databricks-Setup\" data-toc-modified-id=\"Optional:-For-Databricks-Setup-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Optional: For Databricks Setup</a></span></li></ul></li><li><span><a href=\"#Step-3:-Create-a-Spark-DataFrame\" data-toc-modified-id=\"Step-3:-Create-a-Spark-DataFrame-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Step 3: Create a Spark DataFrame</a></span></li><li><span><a href=\"#Exploring-the-DataFrame\" data-toc-modified-id=\"Exploring-the-DataFrame-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Exploring the DataFrame</a></span><ul class=\"toc-item\"><li><span><a href=\"#Count-the-Words-in-the-First-Row\" data-toc-modified-id=\"Count-the-Words-in-the-First-Row-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Count the Words in the First Row</a></span></li><li><span><a href=\"#A-Few-More-Basic-Commands\" data-toc-modified-id=\"A-Few-More-Basic-Commands-2.5.2\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>A Few More Basic Commands</a></span></li></ul></li><li><span><a href=\"#Reading-files\" data-toc-modified-id=\"Reading-files-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Reading files</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/flatiron-school/ds-spark/blob/main/spark-programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for Google Colab environment\n",
    "!pip install pyspark==3.2.1\n",
    "!apt install openjdk-8-jdk-headless -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import ArrayType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use `pyspark` to manipulate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "aff0ce01-e486-4e8c-be60-9022526bc6fe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Spark: Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2601af14-bfc3-47bb-a24c-2544bcb9e674",
     "showTitle": false,
     "title": ""
    },
    "heading_collapsed": true
   },
   "source": [
    "## Optional Step 0: Prerequisites & Installation for Databricks or Local Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> If you run this notebook in Google Colab (clicking the button at the beginning of this notebook that says \"*Open in Colab*\") you can skip to [Step 1](#Step-1:-Create-a-SparkSession-with-a-SparkContext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Databricks Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2601af14-bfc3-47bb-a24c-2544bcb9e674",
     "showTitle": false,
     "title": ""
    },
    "hidden": true
   },
   "source": [
    "Follow [these instructions](https://docs.databricks.com/notebooks/notebooks-manage.html#import-a-notebook) to import this notebook into Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For local installation see [here](https://github.com/learn-co-curriculum/dsc-spark-docker-installation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2b1411e7-bd55-4320-b501-5d1c3f2b5e7b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 1: Create a SparkSession with a SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "789329b9-b2d0-4dfc-af31-8e320bbc1887",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "646e3ec5-bb21-4df6-88dc-c7135d0b2455",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 2: Download some Amazon reviews (Toys & Games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f61a7c8c-e7db-4981-8354-c65b8f8ae326",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get data directly from repo\n",
    "!wget https://github.com/flatiron-school/ds-spark/releases/download/v1.0/reviews_Toys_and_Games_5.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Optional: For Databricks Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "654b4a58-ef41-4d5a-81cf-47461551087b",
     "showTitle": false,
     "title": ""
    },
    "hidden": true
   },
   "source": [
    "Follow [these instructions](https://docs.databricks.com/data/data.html#import-data-1) to import `reviews_Toys_and_Games_5.json` into Databricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fdac9228-261d-4c0c-b4ff-9fcfcd972830",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 3: Create a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3225c644-ef23-4ee9-9d2b-46fc578811ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# this file path will be different if you are running Spark locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "49e85347-dccb-4b1d-ae5b-858984be845d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Persistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "840ef494-2da1-4f21-822e-35f50946d1b2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This last command, `.persist()`, simply stores the DataFrame in memory. See [this page](https://unraveldata.com/to-cache-or-not-to-cache/). It is similar to `.cache()`, but actually more flexible than the latter since you can specify which storage level you want. See [here](https://stackoverflow.com/questions/26870537/what-is-the-difference-between-cache-and-persist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2ac4f27c-75e6-4800-bbae-8635e46c61f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pandas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3755a345-94e2-43f7-8f68-89eb7b17f672",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The 'nullable = true' bit means that the relevant column tolerates null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e3d146c-e3c1-4d19-ac82-22db78214fdc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3eb4b79a-a098-4acf-a5b0-80fcff1ff1b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sort!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "67cc3b28-b436-4695-9317-f3997b60e748",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ca103060-bd12-40e3-bda4-68e235a62cd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ya'll remember SQL, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "720ba532-483c-41ac-b31a-d6c022b31ed3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Convert to RDD!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "749b839f-72f3-4f7a-b568-c3f1961f128c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Count the Words in the First Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f72dec72-0ea2-4fbc-ac3b-df83fb71095c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4ba88cbc-649b-44d2-be0a-25e85e9366d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5b7f69d2-917b-4b15-ba47-4fe656debf4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Remember that we set the default number of lines to show at 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4ae2b8dc-c83d-4dd9-9cc3-371d474f8d4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#'udf' is for User Defined Function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4ae2b8dc-c83d-4dd9-9cc3-371d474f8d4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Registering our word_count() function so that we\n",
    "# can use it with SQL! See documentation here:\n",
    "# https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-UDFRegistration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2d2875cb-375b-4ba5-b089-00a0302dc549",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Now we can use our function in a SQL query!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f6697610-c546-458b-b19f-06d834c4a948",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def count_all_the_things(text):\n",
    "    return [len(text), len(text.split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "06dda3a0-bbbd-4f55-9f41-fea2d215f28f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "count_udf = F.udf(count_all_the_things, returnType=ArrayType(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "eccd843f-e332-45f7-b792-51469fab6fda",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### A Few More Basic Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "eccd843f-e332-45f7-b792-51469fab6fda",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Please refer also to the [official programming guide](http://spark.apache.org/docs/latest/rdd-programming-guide.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ba3b72c4-ef42-4e70-83eb-a4864f672370",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def multiply(a, b):\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d5cbbe3a-84c6-4b80-ada1-47d0d1623d6a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Reading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d5cbbe3a-84c6-4b80-ada1-47d0d1623d6a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "[`sc.textFile()`](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.SparkContext.textFile.html) for .txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c047102e-d814-41a9-a2c2-e48419456197",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "[`.toJSON()`](https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.toJSON.html) for .json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "02-spark-programming",
   "notebookOrigID": 835564910129573,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
